---
layout: colab
title:  Train a simple sentiment classifier on Hugging Face
date:   2024-03-23
---

<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># Run this first to install all the packages needed in this colab. This can take several minutes.</span>
<span class="o">%%</span><span class="n">capture</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">huggingface_hub</span> <span class="n">accelerate</span> <span class="n">transformers</span> <span class="n">datasets</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h1 id="Train-a-simple-sentiment-classifier-on-Hugging-Face">Train a simple sentiment classifier on Hugging Face<a class="anchor-link" href="#Train-a-simple-sentiment-classifier-on-Hugging-Face">&#182;</a></h1><p>This colab walks you through the most simple example of fine-tuning an LLM on Hugging Face. This is part of www.huggingfacetutorial.com.</p>
<p>We start with a 33M parameter pretrained LLM model <a href="https://huggingface.co/microsoft/MiniLM-L12-H384-uncased">MiniLM</a>. We fine-tune the pretrained model with the <a href="https://huggingface.co/datasets/imdb">IMDB datasets</a>, which are review comments on a movie review website tied to a postive or negative sentiment.</p>
<p>The fine-tuned model is a sentiment classifier. You input any text, and it will output the percentage positive and percentage negative.</p>
<p>Be warned: the model this colab creates is not very good at its job. But it's a start. This colab has been stripped down to the bare bones of what is needed to fine-tune a model on Hugging Face using the Transformers library.</p>
<p>You can run this on a regular free Python 3 Google Compute Engine backend. You do not need a GPU or TPU. For those new to colabs and AI modeling, training models require lots of compute power. www.huggingfacetutorial.com tries to teach you the skills and concepts without having to pay for expensive GPU time.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-python"><pre><span></span><span class="c1">#@title [Prework] Login with Hugging Face so that you can upload your trained model to Hugging Face Hub.</span>
<span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">login</span>
<span class="n">login</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>VBox(children=(HTML(value=&#39;&lt;center&gt; &lt;img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-python"><pre><span></span><span class="c1">#@title 1) Load datasets</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="n">dataset_name</span> <span class="o">=</span> <span class="s1">'imdb'</span> <span class="c1">#@param {type:'string'}</span>
<span class="n">full_datasets</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset_name</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Downloading readme:   0%|          | 0.00/7.81k [00:00&lt;?, ?B/s]</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Downloading data:   0%|          | 0.00/21.0M [00:00&lt;?, ?B/s]</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Downloading data:   0%|          | 0.00/20.5M [00:00&lt;?, ?B/s]</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Downloading data:   0%|          | 0.00/42.0M [00:00&lt;?, ?B/s]</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Generating train split:   0%|          | 0/25000 [00:00&lt;?, ? examples/s]</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Generating test split:   0%|          | 0/25000 [00:00&lt;?, ? examples/s]</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Generating unsupervised split:   0%|          | 0/50000 [00:00&lt;?, ? examples/s]</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-python"><pre><span></span><span class="c1">#@title 2) Split dataset into training and eval sets</span>
<span class="n">train_set_name</span> <span class="o">=</span> <span class="s1">'train'</span> <span class="c1">#@param {type:'string'}</span>
<span class="n">eval_set_name</span> <span class="o">=</span> <span class="s1">'test'</span> <span class="c1">#@param {type:'string'}</span>
<span class="n">train_set_sample_size</span> <span class="o">=</span> <span class="mi">1000</span> <span class="c1">#@param {type:'integer'}</span>
<span class="n">eval_set_sample_size</span> <span class="o">=</span> <span class="mi">1000</span> <span class="c1">#@param {type:'integer'}</span>
<span class="n">small_train_dataset</span> <span class="o">=</span> <span class="n">full_datasets</span><span class="p">[</span><span class="n">train_set_name</span><span class="p">]</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">train_set_sample_size</span><span class="p">))</span>
<span class="n">small_eval_dataset</span> <span class="o">=</span> <span class="n">full_datasets</span><span class="p">[</span><span class="n">eval_set_name</span><span class="p">]</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">eval_set_sample_size</span><span class="p">))</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-python"><pre><span></span><span class="c1">#@title 3) Get model and tokenizer</span>
<span class="n">pretrained_model</span> <span class="o">=</span> <span class="s1">'microsoft/MiniLM-L12-H384-uncased'</span> <span class="c1">#@param {type:'string'}</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>config.json:   0%|          | 0.00/385 [00:00&lt;?, ?B/s]</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>pytorch_model.bin:   0%|          | 0.00/133M [00:00&lt;?, ?B/s]</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: [&#39;classifier.bias&#39;, &#39;classifier.weight&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>tokenizer_config.json:   0%|          | 0.00/2.00 [00:00&lt;?, ?B/s]</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>vocab.txt:   0%|          | 0.00/232k [00:00&lt;?, ?B/s]</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>special_tokens_map.json:   0%|          | 0.00/112 [00:00&lt;?, ?B/s]</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-python"><pre><span></span><span class="c1">#@title 4) Tokenize datasets</span>
<span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s1">'text'</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">'max_length'</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">tokenized_train_dataset</span> <span class="o">=</span> <span class="n">small_train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">tokenized_eval_dataset</span> <span class="o">=</span> <span class="n">small_eval_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Map:   0%|          | 0/1000 [00:00&lt;?, ? examples/s]</pre>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>




<div class="jp-RenderedText jp-OutputArea-output " data-mime-type="text/plain">
<pre>Map:   0%|          | 0/1000 [00:00&lt;?, ? examples/s]</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-python"><pre><span></span><span class="c1">#@title 5) Prepare Trainer</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>
<span class="n">output_dir</span><span class="o">=</span><span class="s1">'sentiment-guesser'</span> <span class="c1">#@param {type:'string'}</span>
<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="n">output_dir</span><span class="o">=</span><span class="n">output_dir</span><span class="p">,</span>
                                  <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                  <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s1">'epoch'</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-python"><pre><span></span><span class="c1">#@title 6) Create Trainer</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">tokenized_train_dataset</span><span class="p">,</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">tokenized_eval_dataset</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys([&#39;dispatch_batches&#39;, &#39;split_batches&#39;, &#39;even_batches&#39;, &#39;use_seedable_sampler&#39;]). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-python"><pre><span></span><span class="c1">#@title 7) Train and save to Hugging Face</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output " data-mime-type="text/html">

    <div>
      
      <progress value='54' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [ 54/125 22:19 < 30:29, 0.04 it/s, Epoch 0.42/1]
    </div>
    <table border="1" class="dataframe">
  <thead>
 <tr style="text-align: left;">
      <th>Epoch</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table><p>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-11-faa0353ed0c2&gt;</span> in <span class="ansi-cyan-fg">&lt;cell line: 2&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg">#@title 7) Train and save to Hugging Face</span>
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg"> </span>trainer<span class="ansi-blue-fg">.</span>train<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span> trainer<span class="ansi-blue-fg">.</span>push_to_hub<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.10/dist-packages/transformers/trainer.py</span> in <span class="ansi-cyan-fg">train</span><span class="ansi-blue-fg">(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1622</span>                 hf_hub_utils<span class="ansi-blue-fg">.</span>enable_progress_bars<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1623</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 1624</span><span class="ansi-red-fg">             return inner_training_loop(
</span><span class="ansi-green-intense-fg ansi-bold">   1625</span>                 args<span class="ansi-blue-fg">=</span>args<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1626</span>                 resume_from_checkpoint<span class="ansi-blue-fg">=</span>resume_from_checkpoint<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/usr/local/lib/python3.10/dist-packages/transformers/trainer.py</span> in <span class="ansi-cyan-fg">_inner_training_loop</span><span class="ansi-blue-fg">(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)</span>
<span class="ansi-green-intense-fg ansi-bold">   1959</span> 
<span class="ansi-green-intense-fg ansi-bold">   1960</span>                 <span class="ansi-green-fg">with</span> self<span class="ansi-blue-fg">.</span>accelerator<span class="ansi-blue-fg">.</span>accumulate<span class="ansi-blue-fg">(</span>model<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 1961</span><span class="ansi-red-fg">                     </span>tr_loss_step <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>training_step<span class="ansi-blue-fg">(</span>model<span class="ansi-blue-fg">,</span> inputs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1962</span> 
<span class="ansi-green-intense-fg ansi-bold">   1963</span>                 if (

<span class="ansi-green-fg">/usr/local/lib/python3.10/dist-packages/transformers/trainer.py</span> in <span class="ansi-cyan-fg">training_step</span><span class="ansi-blue-fg">(self, model, inputs)</span>
<span class="ansi-green-intense-fg ansi-bold">   2909</span>                 scaled_loss<span class="ansi-blue-fg">.</span>backward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   2910</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 2911</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>accelerator<span class="ansi-blue-fg">.</span>backward<span class="ansi-blue-fg">(</span>loss<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   2912</span> 
<span class="ansi-green-intense-fg ansi-bold">   2913</span>         <span class="ansi-green-fg">return</span> loss<span class="ansi-blue-fg">.</span>detach<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">/</span> self<span class="ansi-blue-fg">.</span>args<span class="ansi-blue-fg">.</span>gradient_accumulation_steps

<span class="ansi-green-fg">/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py</span> in <span class="ansi-cyan-fg">backward</span><span class="ansi-blue-fg">(self, loss, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1999</span>             self<span class="ansi-blue-fg">.</span>scaler<span class="ansi-blue-fg">.</span>scale<span class="ansi-blue-fg">(</span>loss<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>backward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   2000</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 2001</span><span class="ansi-red-fg">             </span>loss<span class="ansi-blue-fg">.</span>backward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   2002</span> 
<span class="ansi-green-intense-fg ansi-bold">   2003</span>     <span class="ansi-green-fg">def</span> set_trigger<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/lib/python3.10/dist-packages/torch/_tensor.py</span> in <span class="ansi-cyan-fg">backward</span><span class="ansi-blue-fg">(self, gradient, retain_graph, create_graph, inputs)</span>
<span class="ansi-green-intense-fg ansi-bold">    520</span>                 inputs<span class="ansi-blue-fg">=</span>inputs<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    521</span>             )
<span class="ansi-green-fg">--&gt; 522</span><span class="ansi-red-fg">         torch.autograd.backward(
</span><span class="ansi-green-intense-fg ansi-bold">    523</span>             self<span class="ansi-blue-fg">,</span> gradient<span class="ansi-blue-fg">,</span> retain_graph<span class="ansi-blue-fg">,</span> create_graph<span class="ansi-blue-fg">,</span> inputs<span class="ansi-blue-fg">=</span>inputs
<span class="ansi-green-intense-fg ansi-bold">    524</span>         )

<span class="ansi-green-fg">/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py</span> in <span class="ansi-cyan-fg">backward</span><span class="ansi-blue-fg">(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)</span>
<span class="ansi-green-intense-fg ansi-bold">    264</span>     <span class="ansi-red-fg"># some Python versions print out the first line of a multi-line function</span>
<span class="ansi-green-intense-fg ansi-bold">    265</span>     <span class="ansi-red-fg"># calls in the traceback and some print out the last line</span>
<span class="ansi-green-fg">--&gt; 266</span><span class="ansi-red-fg">     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
</span><span class="ansi-green-intense-fg ansi-bold">    267</span>         tensors<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    268</span>         grad_tensors_<span class="ansi-blue-fg">,</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>

</div>

</div>
